
# Execution Units

Module: Computer Systems Organization

---

## 1.2.0 Introduction to Computational Engines

The CPU is not a monolith; it is a collection of specialized engines. The **ALU** and **FPU** are the "muscles" that transform binary inputs into outputs during the **Execute (EX)** stage of the pipeline.

- **ALU (Arithmetic Logic Unit):** Handles Integers (`int`, `long`) and Boolean logic. It is the workhorse for control flow (comparisons) and memory address calculations.
    
- **FPU (Floating Point Unit):** Handles Real numbers (`float`, `double`). It implements the **IEEE 754** standard.
    

> **Why this matters:** Understanding the split between ALU and FPU is critical for **Compiler Optimization** (instruction scheduling) and **OS Scheduling** (context switch overhead).

---

## 1.2.1 The Arithmetic Logic Unit (ALU)

### 1.2.1.1 Internal Architecture

The ALU is composed of combinational logic circuits. As described in foundational texts like Petzold‚Äôs _Code_, it relies on:

1. **Logic Gates:** AND, OR, XOR, NOT.
    
2. **Multiplexers (MUX):** To select inputs/outputs.
    
3. **Adders:** The core arithmetic circuit.
    

### 1.2.1.2 The Adder Hierarchy

- **Ripple Carry Adder:** Simple design using a cascade of Full Adders.
    
    - _Constraint:_ Propagation delay grows linearly with bit-width (the "Carry" must ripple from bit 0 to bit 63).
        
- **Carry-Lookahead Adder (CLA):** Modern standard.
    
    - _Optimization:_ Computes carry bits in parallel using complex logic, reducing latency.
        

![Image of 4-bit Ripple Carry Adder diagram](https://encrypted-tbn3.gstatic.com/licensed-image?q=tbn:ANd9GcS2-37_Y2xCUVZ2WkSEH6oGgUOi1jD2dIm2maTUlFBxzA-2BlYA9TG39dEBXH5P9MmmrkjqhebftsQGDDOwNhBuTOR9NvOrToEBrqvTvACTXX2tkiI)

### 1.2.1.3 Specialized ALU Hardware: The Barrel Shifter

A hardware circuit capable of shifting or rotating a data word by $n$ bits in a **single clock cycle**.

- **Use Cases:** Bitmasking, Cryptography, Graphics.
    
- **Without it:** Shifting by 5 bits would require 5 separate "shift" instructions.
    

---

## 1.2.2 The Floating Point Unit (FPU)

### 1.2.2.1 IEEE 754 Representation

While integers are exact, floating-point numbers are approximations represented scientifically.

$$V = (-1)^s \times (1.m) \times 2^{(e - bias)}$$

**The 3 Components:**

1. **Sign ($s$):** 1 bit (0 for positive, 1 for negative).
    
2. **Exponent ($e$):** biased integer (8 bits for Single Precision).
    
3. **Mantissa ($m$):** The fractional component (23 bits for Single Precision).
    

### 1.2.2.2 Walkthrough Example

**Target Binary:** `0 10000001 0010000...`

- **Sign:** 0 (+)
    
- **Exponent:** `10000001` = 129. Bias is 127. $\text{Effective Exponent} = 129 - 127 = 2$.
    
- **Mantissa:** `1.001` (binary) = $1 + 0.125 = 1.125$ (decimal).
    
- **Calculation:** $1.125 \times 2^2 = 1.125 \times 4 = \mathbf{4.5}$.
    

### 1.2.2.3 Microarchitectural Enhancement: Fused Multiply-Add (FMA)

Modern FPUs (and GPUs) use FMA to perform two operations in one rounded step.

$$\text{Operation: } \mathbf{R} = (a \times b) + c$$

- **Benefits:** Higher precision (only one rounding step) and throughput.
    
- **Applications:** Critical for **Machine Learning** (Matrix Multiplication) and Digital Signal Processing (DSP).
    

---

## 1.2.3 Pipeline Integration & Parallelism

### 1.2.3.1 Superscalar Execution

In the **Execute (EX)** stage, modern CPUs can dispatch multiple instructions to different units simultaneously. This is **Instruction Level Parallelism (ILP)**.

|**Unit Type**|**Operation Class**|**Example Instruction**|
|---|---|---|
|**ALU #1**|Integer Add|`add x5, x1, x2`|
|**ALU #2**|Logic / Compare|`slt x6, x3, x4`|
|**FPU #1**|Float Math|`fmul.s f1, f2, f3`|
|**SIMD Unit**|Vector Math|`vadd.vv v1, v2, v3`|

### 1.2.3.2 Workload Classification

- **ALU-Bound:** Data Compression, Compilers, OS Kernels.
    
    - _Symptom:_ ALUs saturated; FPUs idle.
        
- **FPU-Bound:** Scientific Simulation, 3D Rendering, ML Inference.
    
    - _Symptom:_ FPUs saturated.
        

---

## 1.2.4 OS-Level Visibility

The Operating System treats the ALU and FPU as resources that must be managed during **Context Switches**.

1. **State Preservation:** When switching threads, the OS must save the contents of all registers.
    
    - _Impact:_ FPU/SIMD registers (often 256 or 512 bits wide) are much larger than ALU registers. Excessive context switching in FPU-heavy apps causes memory bandwidth pressure.
        
2. **Exception Handling:**
    
    - **ALU Exception:** `Division by Zero` (Integer).
        
    - **FPU Exception:** `NaN` (Not a Number), `Underflow`.
        
    - _Mechanism:_ The hardware triggers a trap; the OS kernel catches it and sends a signal (e.g., `SIGFPE` in Linux) to the process.
        

---

## üìù Section Quiz

1. Mathematical Verification

Given an IEEE 754 number where Sign=0, Exponent=10000000 (128), and Mantissa=100... (1.5). Calculate the decimal value.

(Hint: Bias is 127).

2. Conceptual Analysis

Why can a conditional branch instruction (if x > y) NOT be executed purely by the ALU in a pipelined processor?

(Consider: The ALU calculates the comparison, but what updates the PC?)

3. System Design

You are designing a CPU for a cryptographic server. Would you prioritize adding more FPU units or more Barrel Shifters? Why?

---

## üîó Connective Tissue

- **‚óÄÔ∏è Previous (1.1):** The Instruction Cycle (Where Fetch/Decode happen before reaching the ALU).
    
- **‚ñ∂Ô∏è Next (1.3):** **Pipelining**. We will explore how the ALU and FPU act as distinct stages in the pipeline to allow overlapping execution.
    
