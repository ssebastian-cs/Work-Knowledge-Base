# Cache Architecture

Module: Computer Systems Organization

---

## 1.5.0 The Motivation: The "Memory Wall"

The speed gap between the CPU and Main Memory (DRAM) is exponential.

- **CPU Cycle:** $\approx 0.3$ nanoseconds (3+ GHz).
    
- **DRAM Access:** $\approx 100$ nanoseconds.
    

If a CPU had to wait for DRAM for every instruction, it would be idle $>99\%$ of the time. **Caches** are small, fast SRAM buffers designed to bridge this gap.

|**Memory Tier**|**Typical Size**|**Latency (Cycles)**|**Visibility**|
|---|---|---|---|
|**Registers**|$< 1$ KB|$1$|Compiler / ASM|
|**L1 Cache**|$32 \text{-} 64$ KB|$4$|Hardware|
|**L2 Cache**|$256 \text{-} 512$ KB|$12$|Hardware|
|**L3 Cache (LLC)**|$8 \text{-} 64$ MB|$40 \text{-} 60$|Hardware|
|**DRAM (RAM)**|$16 \text{-} 64$ GB|$200+$|OS / Application|

---

## 1.5.1 The Two Principles of Locality

Caches work because computer programs are predictable.

1. **Temporal Locality:** If you used a data item recently, you will likely use it again soon.
    
    - _Example:_ Loop counters (`i`), local variables.
        
2. **Spatial Locality:** If you access address $X$, you will likely access $X+1$ soon.
    
    - _Example:_ Iterating through an array or executing sequential code.
        

C

```
// Demonstrating Both:
for (int i = 0; i < 1000; i++) {
    sum += array[i]; 
    // Temporal: 'sum' and 'i' are accessed repeatedly.
    // Spatial: array[i] is followed immediately by array[i+1].
}
```

---

## 1.5.2 Cache Structure & Addressing

### The Cache Line (Block)

Data is transferred between memory and cache in chunks called **Lines** (typically **64 bytes**).

- _implication:_ Asking for 1 byte actually loads 64 bytes. This essentially "pre-fetches" neighbors, exploiting Spatial Locality.
    

### Address Decomposition

To find data, the CPU splits the physical address into three parts:

1. **Tag:** Unique identifier to confirm "Is this the data I requested?"
    
2. **Index:** Selects which "row" (Set) in the cache to look in.
    
3. **Offset:** Selects the specific byte within the 64-byte line.
    

### Mathematics of Addressing

Given:

- Cache Size: $C$
    
- Line Size: $L$ (usually 64)
    
- Associativity: $W$ (Ways)
    

$$\text{Number of Sets} (S) = \frac{C}{L \times W}$$

$$\text{Index Bits} = \log_2(S)$$

$$\text{Offset Bits} = \log_2(L)$$

---

## 1.5.3 Associativity & Placement

How strictly does the hardware enforce _where_ data can sit?

1. **Direct Mapped (1-Way):**
    
    - Address $X$ can only go into **one specific slot**.
        
    - _Pro:_ Fast lookup.
        
    - _Con:_ High **Conflict Misses** (Ping-ponging if two active variables map to the same slot).
        
2. **N-Way Set Associative (Modern Standard):**
    
    - Address $X$ can go into any of $N$ slots within a specific set.
        
    - _Typical:_ L1 is 8-Way; L3 is 16-Way.
        
    - _Benefit:_ Drastically reduces conflicts.
        
3. **Fully Associative:**
    
    - Any address can go anywhere. (Too slow/expensive for data caches; used for TLBs).
        

---

## 1.5.4 Cache Miss Types (The "3 Cs")

1. **Compulsory (Cold):** The very first time data is accessed. Unavoidable.
    
2. **Capacity:** The cache is simply too small to hold the current working set.
    
3. **Conflict:** Space is available in the cache, but not in the _specific set_ mapped to this address. (Solved by increasing Associativity).
    

---

## 1.5.5 Multicore Coherence (MESI Protocol)

In a multicore system, Core A and Core B might cache the same address. If Core A writes to it, Core B's copy becomes stale (wrong).

The MESI Protocol ensures all cores see a consistent view of memory.Shutterstock

- **M (Modified):** I have the only valid copy, and I have modified it (Dirty).
    
- **E (Exclusive):** I have the only valid copy, but it matches RAM (Clean).
    
- **S (Shared):** Multiple cores have this copy (Read-only).
    
- **I (Invalid):** My copy is garbage.
    

> Performance Killer: False Sharing
> 
> If Core A writes to Variable X and Core B writes to Variable Y, but X and Y sit on the same 64-byte cache line, the line will "bounce" between cores.
> 
> Result: $20\times$ performance degradation.
> 
> Fix: Pad variables to ensure they are on different lines.

---

## 1.5.6 OS-Level Interaction

The Operating System is aware of the cache topology.

1. **Processor Affinity:** The Scheduler tries to keep a thread on the same core to preserve **"Cache Warmth"** (L1/L2 data is already present).
    
2. **NUMA (Non-Uniform Memory Access):** In large servers, RAM is attached to specific CPU sockets. Accessing "local" RAM is faster than "remote" RAM.
    

---

## üìù Problem Set

### 1. Address Decoding

Given: A 32KB L1 Cache, 4-Way Set Associative, 64-byte lines.

Task: Calculate the bit-widths for Offset, Index, and Tag for a 32-bit address.

Solution:

1. $\text{Offset} = \log_2(64) = \mathbf{6 \text{ bits}}$.
    
2. $\text{Sets} = \frac{32 \text{KB}}{64 \text{B} \times 4} = \frac{32768}{256} = 128 \text{ sets}$.
    
3. $\text{Index} = \log_2(128) = \mathbf{7 \text{ bits}}$.
    
4. $\text{Tag} = 32 - (7 + 6) = \mathbf{19 \text{ bits}}$.
    

### 2. Code Optimization

Scenario: You are traversing a 2D matrix int matrix[1024][1024].

Question: Why is row-major traversal (matrix[i][j]) vastly faster than column-major (matrix[j][i]) in C/C++?

Answer: Row-major access accesses contiguous memory addresses ($x, x+4, x+8$), exploiting Spatial Locality (one cache line load serves 16 integers). Column-major access jumps by 1024 integers ($4096$ bytes) every step, causing a Cache Miss on every single access.

### 3. False Sharing

**Scenario:** A multithreaded counter.

C

```
struct {
   long coreA_count;
   long coreB_count;
} global_counts;
```

Critique: These two longs (8 bytes each) sit side-by-side. They will fit in the same 64-byte cache line. When Core A updates its count, it invalidates Core B's cache line, and vice versa.

Fix: Add char padding[64] between the variables.

---

## üîó Connection Links

- **‚óÄÔ∏è Previous (1.4):** **OoOE**. (The CPU uses OoO to find other work to do while waiting for these Cache Misses).
    
- **‚ñ∂Ô∏è Next (1.6):** **Branch Prediction**. (Just as Caches predict _data_ usage, Branch Predictors predict _code_ paths).
    