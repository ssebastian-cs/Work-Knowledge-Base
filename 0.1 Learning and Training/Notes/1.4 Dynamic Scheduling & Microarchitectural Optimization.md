# Out-of-Order Execution (OoOE)

Module: Computer Systems Organization

---

## 1.4.0 The Core Philosophy

**Out-of-Order Execution (OoOE)** is the microarchitectural technique that allows a processor to execute instructions as soon as their data operands are ready, rather than waiting for previous instructions to finish.

### The "Illusion of Sequential Consistency"

The most important rule in CPU design: **The hardware may cheat, but it must not get caught.**

- **Internally:** The CPU is a chaotic, parallel storm of execution.
    
- **Externally (to the OS/Programmer):** Instructions appear to finish in exact program order (1, 2, 3, 4...).
    

> **Motivation:** To hide latency. If an instruction stalls (e.g., a cache miss takes 200 cycles), an In-Order CPU freezes. An OoO CPU simply skips ahead to find other useful work.

---

## 1.4.1 The Hardware Architecture (Tomasuloâ€™s Legacy)

Modern OoOE is based on **Tomasuloâ€™s Algorithm** (IBM 360/91). It introduces specific hardware buffers to decouple the pipeline stages.

### Key Components

|**Component**|**Function**|**Analogy**|
|---|---|---|
|**Reservation Stations (RS)**|Buffer instructions waiting for operands (inputs).|A waiting room for math problems.|
|**Reorder Buffer (ROB)**|Tracks the status of every in-flight instruction to ensure they finish in order.|The "ticket taker" at the exit.|
|**Physical Register File (PRF)**|A large pool of actual registers (e.g., 168 hardware registers) mapped to the limited architectural registers (e.g., 16 x86 registers).|The actual storage locker.|
|**Common Data Bus (CDB)**|Broadcasts results from execution units to waiting stations.|The PA system announcing results.|
|**Load/Store Queue (LSQ)**|Manages memory order and detects conflicts between reads and writes.|The shipping & receiving log.|

---

## 1.4.2 The OoO Pipeline Stages

In modern x86/ARM processors, the flow is hybrid: **In-Order Front End** $\to$ **Out-of-Order Core** $\to$ **In-Order Back End**.

1. **Fetch & Decode (In-Order):** Instructions enter the pipeline.
    
2. **Rename (In-Order):** Architectural registers (e.g., `rax`) are mapped to physical registers (e.g., `p45`) to remove false dependencies.
    
3. **Dispatch (In-Order):** Instructions move to Reservation Stations and the ROB.
    
4. **Issue & Execute (Out-of-Order):** The moment operands are ready, the instruction runs. Order does not matter here.
    
5. **Write Back:** Results are broadcast on the CDB.
    
6. **Commit/Retire (In-Order):** The ROB checks if the oldest instruction is done. If yes, it updates the architectural state. This guarantees **Precise Exceptions**.
    

---

## 1.4.3 Register Renaming: Removing False Dependencies

Hazards limit parallelism. Renaming solves two specific types: **WAR** (Write-After-Read) and **WAW** (Write-After-Write).

**The Problem (False Dependency):**

Code snippet

```
1. add x1, x2, x3    ; Writes to x1
2. mul x1, x4, x5    ; Writes to x1 again (WAW Hazard)
```

_In a physical sense, line 2 doesn't need the data from line 1. It just wants to use the name `x1`._

The Solution (Renaming):

The CPU renames x1 to unique physical registers (p).

Code snippet

```
1. add p10, p2, p3   ; "x1" is now p10
2. mul p11, p4, p5   ; "x1" is now p11
```

_Result:_ Both instructions can now execute simultaneously.

---

## 1.4.4 Memory Disambiguation (Load/Store Queues)

Memory is trickier than registers because addresses are calculated at runtime.

- **The Hazard:** `sw x1, 0(x2)` followed by `lw x3, 0(x4)`.
    
- **The Question:** Does Address `0(x2)` equal Address `0(x4)`?
    
- **Store-to-Load Forwarding:** If the LSQ detects the addresses match, it effectively "teleports" the data from the Store buffer directly to the Load, skipping main memory entirely.
    

---

## 1.4.5 Critical Security Context: Meltdown & Spectre

OoOE is the root cause of the most significant CPU vulnerabilities of the last decade.

- **The Mechanism:** CPUs **speculate** (guess). They execute instructions past a branch before knowing if the branch is taken.
    
- **The Flaw:** If the guess is wrong, the CPU rolls back the _architectural_ state (registers), but it may leave footprints in the _microarchitectural_ state (Cache).
    
- **The Exploit:** Attackers force the CPU to speculatively load secret data (like kernel passwords) into the cache, then measure cache timing to read it (Side-Channel Attack).
    

---

## 1.4.6 Walkthrough: Hiding Latency

**Scenario:** A Cache Miss.

|**Instruction**|**Dependency**|**Status (In-Order CPU)**|**Status (OoO CPU)**|
|---|---|---|---|
|`1. lw x1, 0(x2)`|**L1 Cache Miss (200 cycles)**|**Stalls pipeline**|Stalls, but waits in ROB.|
|`2. add x3, x4, x5`|Independent|Waits for Instr 1|**Executes Immediately.**|
|`3. mul x6, x7, x8`|Independent|Waits for Instr 1|**Executes Immediately.**|
|`4. sub x1, x3, x6`|Depends on x1, x3, x6|Waits for Instr 1|Waits only for x1 (Instr 1).|

_In the OoO CPU, the math (Instr 2 & 3) is done for "free" while waiting for memory._

---

## ğŸ“ Problem Set

### 1. Dependency Analysis

**Code:**

Code snippet

```
1. div x1, x2, x3    ; Long latency operation
2. add x4, x1, x5    ; RAW dependency on x1
3. sub x2, x6, x7    ; WAR dependency on x2
```

Task: Explain how OoOE handles instruction 3.

Answer: Through Register Renaming, instruction 3 is not blocked. The x2 in instruction 3 is mapped to a different physical register than the x2 read in instruction 1. Instruction 3 executes immediately, likely finishing before instruction 1.

### 2. The Commit Constraint

Question: Why must instructions retire (commit) in order, even if they executed out of order?

Answer: To handle Exceptions and Interrupts correctly. If instruction 2 crashes (e.g., divide by zero), the CPU must ensure that instruction 1 has completed and instruction 3 has not updated the permanent state yet.

### 3. Diagramming

**Task:** Draw a dependency graph for the following.

Code snippet

```
lw x1, 0(x2)
add x3, x1, x4
sub x5, x6, x7
```

**Hint:** `lw` -> `add` is a solid line (True Dependency). `sub` is an isolated node (Independent).

---

## ğŸ”— Connection Links

- **â—€ï¸ Previous (1.3):** Pipelining (The foundation OoOE builds upon).
    
- **â–¶ï¸ Next (1.5):** **Cache Hierarchy**. (We mentioned "Cache Misses" here; next we explain why they happen and how the hierarchy works).
    